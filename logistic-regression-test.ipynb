{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt \nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create train data set\ntrain_df = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create test data set\ntest_df = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data quality and missing values\ntrain_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#percent of missing values\nprint('Percent of missing \"homeplanet\" records is %.2f%%' %((train_df['HomePlanet'].isnull().sum()/train_df.shape[0])*100))\nprint('Percent of missing \"cryosleep\" records is %.2f%%' %((train_df['CryoSleep'].isnull().sum()/train_df.shape[0])*100))\nprint('Percent of missing \"Cabin\" records is %.2f%%' %((train_df['Cabin'].isnull().sum()/train_df.shape[0])*100))\nprint('Percent of missing \"Destination\" records is %.2f%%' %((train_df['Destination'].isnull().sum()/train_df.shape[0])*100))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df['HomePlanet'].value_counts())\n#hence impute data with Earth starting point\nprint(train_df['CryoSleep'].value_counts())\n#impute with False\n#drop cabin, not needed\nprint(train_df['Destination'].value_counts())\n#impute with TRAPPIST-1e\nprint('The median of \"Age\" is', (train_df[\"Age\"].median(skipna=True)))\n#impute with 27 years\nprint(train_df['VIP'].value_counts())\n#impute wiht False\nprint('The median of \"RoomSerivice\" is', (train_df[\"RoomService\"].median(skipna=True)))\n#impute with 0\nprint('The median of \"ShoppingMall\" is', (train_df[\"ShoppingMall\"].median(skipna=True)))\n#impute with 0\nprint('The median of \"Spa\" is', (train_df[\"Spa\"].median(skipna=True)))\n#impute with 0\nprint('The median of \"VRDeck\" is', (train_df[\"VRDeck\"].median(skipna=True)))\n#impute with 0\n#drop name, not needed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now actually substitute the valus in\ntrain_data = train_df.copy()\ntrain_data[\"HomePlanet\"].fillna(train_df['HomePlanet'].value_counts().idxmax(), inplace=True)\ntrain_data[\"CryoSleep\"].fillna(train_df['CryoSleep'].value_counts().idxmax(), inplace=True)\ntrain_data[\"Destination\"].fillna(train_df['Destination'].value_counts().idxmax(), inplace=True)\ntrain_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\ntrain_data[\"VIP\"].fillna(train_df['VIP'].value_counts().idxmax(), inplace=True)\ntrain_data[\"RoomService\"].fillna(train_df[\"RoomService\"].median(skipna=True), inplace=True)\ntrain_data[\"ShoppingMall\"].fillna(train_df[\"ShoppingMall\"].median(skipna=True), inplace=True)\ntrain_data[\"Spa\"].fillna(train_df[\"Spa\"].median(skipna=True), inplace=True)\ntrain_data[\"VRDeck\"].fillna(train_df[\"VRDeck\"].median(skipna=True), inplace=True)\ntrain_data[\"FoodCourt\"].fillna(train_df[\"FoodCourt\"].median(skipna=True), inplace=True)\n\ntrain_data.drop('Cabin', axis=1, inplace=True)\ntrain_data.drop('Name', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()\ntraining = pd.get_dummies(train_data, columns=['HomePlanet', 'CryoSleep', 'Destination','VIP', \"Transported\"])\n\n\nfinal_train = training\nfinal_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing values for test set\ntest_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = test_df.copy()\ntest_data[\"HomePlanet\"].fillna(test_df['HomePlanet'].value_counts().idxmax(), inplace=True)\ntest_data[\"CryoSleep\"].fillna(test_df['CryoSleep'].value_counts().idxmax(), inplace=True)\ntest_data[\"Destination\"].fillna(test_df['Destination'].value_counts().idxmax(), inplace=True)\ntest_data[\"Age\"].fillna(test_df[\"Age\"].median(skipna=True), inplace=True)\ntest_data[\"VIP\"].fillna(test_df['VIP'].value_counts().idxmax(), inplace=True)\ntest_data[\"RoomService\"].fillna(test_df[\"RoomService\"].median(skipna=True), inplace=True)\ntest_data[\"ShoppingMall\"].fillna(test_df[\"ShoppingMall\"].median(skipna=True), inplace=True)\ntest_data[\"Spa\"].fillna(test_df[\"Spa\"].median(skipna=True), inplace=True)\ntest_data[\"VRDeck\"].fillna(test_df[\"VRDeck\"].median(skipna=True), inplace=True)\ntest_data[\"FoodCourt\"].fillna(test_df[\"FoodCourt\"].median(skipna=True), inplace=True)\n\ntest_data.drop('Cabin', axis=1, inplace=True)\ntest_data.drop('Name', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.isnull().sum()\ntesting = pd.get_dummies(test_data, columns=['HomePlanet', 'CryoSleep', 'Destination','VIP'])\n\n\nfinal_test = testing\nfinal_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#explore the data\n#age graph\nplt.figure(figsize=(15,8))\nax = sns.kdeplot(final_train['Age'][final_train.Transported_True == 1])\nsns.kdeplot(final_train['Age'][final_train.Transported_True == 0])\nplt.legend([\"survived\", \"died\"])\nplt.title(\"density plot\")\nax.set(xlabel=\"age\")\nplt.show","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#room service\nplt.figure(figsize=(15,8))\nax = sns.kdeplot(final_train['RoomService'][final_train.Transported_True == 1])\nsns.kdeplot(final_train['RoomService'][final_train.Transported_True == 0])\nplt.legend([\"survived\", \"died\"])\nplt.title(\"density plot\")\nax.set(xlabel=\"roomservice\")\nplt.show","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#food court\nplt.figure(figsize=(15,8))\nax = sns.kdeplot(final_train['FoodCourt'][final_train.Transported_True == 1])\nsns.kdeplot(final_train['FoodCourt'][final_train.Transported_True == 0])\nplt.legend([\"survived\", \"died\"])\nplt.title(\"density plot\")\nax.set(xlabel=\"foodcourt\")\nplt.show","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shopping mall\nplt.figure(figsize=(15,8))\nax = sns.kdeplot(final_train['ShoppingMall'][final_train.Transported_True == 1])\nsns.kdeplot(final_train['ShoppingMall'][final_train.Transported_True == 0])\nplt.legend([\"survived\", \"died\"])\nplt.title(\"density plot\")\nax.set(xlabel=\"shopping\")\nplt.show","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols = [\"CryoSleep\", \"HomePlanet\", \"Destination\", \"Age\", \"VIP\"]\nX = pd.get_dummies(train_data[feature_cols])\ny = pd.get_dummies(train_data.Transported)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create the RFE Model to see which features are good to keep\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\n\ncols = [\"Age\", \"HomePlanet_Earth\", \"HomePlanet_Europa\", \n        \"HomePlanet_Mars\", \"CryoSleep_True\", \"Destination_55 Cancri e\", \"Destination_PSO J318.5-22\", \"Destination_TRAPPIST-1e\", \"VIP_True\"]\n\nX = final_train[cols]\ny = final_train[\"Transported_True\"]\n\nmodel = LogisticRegression(max_iter=5000)\n\nrfe = RFE(estimator=model, n_features_to_select=14)\nrfe = rfe.fit(X, y)\n\nprint('Selected features: %s' % list(X.columns[rfe.support_]))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test out how many features is most accurate\nfrom sklearn.feature_selection import RFECV\n\nrfecv = RFECV(estimator=LogisticRegression(), step=1, cv=10, scoring='accuracy')\nrfecv.fit(X, y)\n\nprint(\"Optimal number of features: %d\" % rfecv.n_features_)\nprint('Selected features: %s' % list(X.columns[rfecv.support_]))\n\n\nplt.figure(figsize=(10,6))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Selected_features = [\"Age\", \"HomePlanet_Earth\", \"HomePlanet_Europa\", \"HomePlanet_Mars\", \"CryoSleep_True\", \"Destination_55 Cancri e\", \n                    \"Destination_PSO J318.5-22\"]\nX = final_train[Selected_features]\nplt.subplots(figsize=(8, 5))\nsns.heatmap(X.corr(), annot=True, cmap=\"RdYlGn\")\nplt.show()                     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n\n# create X (features) and y (response)\nX = final_train[Selected_features]\ny = final_train['Transported_True']\n\n# use train/test split with different random_state values\n# we can change the random_state values that changes the accuracy scores\n# the scores change a lot, this is why testing scores is a high-variance estimate\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n\n# check classification scores of logistic regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\ny_pred_proba = logreg.predict_proba(X_test)[:, 1]\n[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\nprint('Train/Test split results:')\nprint(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\nprint(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\nprint(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n\nidx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95\n\nplt.figure()\nplt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')\nplt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\nplt.ylabel('True Positive Rate (recall)', fontsize=14)\nplt.title('Receiver operating characteristic (ROC) curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nprint(\"Using a threshold of %.3f \" % thr[idx] + \"guarantees a sensitivity of %.3f \" % tpr[idx] +  \n      \"and a specificity of %.3f\" % (1-fpr[idx]) + \n      \", i.e. a false positive rate of %.2f%%.\" % (np.array(fpr[idx])*100))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10-fold cross-validation logistic regression\nlogreg = LogisticRegression()\n# Use cross_val_score function\n# We are passing the entirety of X and y, not X_train or y_train, it takes care of splitting the data\n# cv=10 for 10 folds\n# scoring = {'accuracy', 'neg_log_loss', 'roc_auc'} for evaluation metric - althought they are many\nscores_accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy')\nscores_log_loss = cross_val_score(logreg, X, y, cv=10, scoring='neg_log_loss')\nscores_auc = cross_val_score(logreg, X, y, cv=10, scoring='roc_auc')\nprint('K-fold cross-validation results:')\nprint(logreg.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())\nprint(logreg.__class__.__name__+\" average log_loss is %2.3f\" % -scores_log_loss.mean())\nprint(logreg.__class__.__name__+\" average auc is %2.3f\" % scores_auc.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nX = final_train[Selected_features]\n\nparam_grid = {'C': np.arange(1e-05, 3, 0.1)}\nscoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\n\ngs = GridSearchCV(LogisticRegression(), return_train_score=True,\n                  param_grid=param_grid, scoring=scoring, cv=10, refit='Accuracy')\n\ngs.fit(X, y)\nresults = gs.cv_results_\n\nprint('='*20)\nprint(\"best params: \" + str(gs.best_estimator_))\nprint(\"best params: \" + str(gs.best_params_))\nprint('best score:', gs.best_score_)\nprint('='*20)\n\nplt.figure(figsize=(10, 10))\nplt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",fontsize=16)\n\nplt.xlabel(\"Inverse of regularization strength: C\")\nplt.ylabel(\"Score\")\nplt.grid()\n\nax = plt.axes()\nax.set_xlim(0, param_grid['C'].max()) \nax.set_ylim(0.35, 0.95)\n\n# Get the regular numpy array from the MaskedArray\nX_axis = np.array(results['param_C'].data, dtype=float)\n\nfor scorer, color in zip(list(scoring.keys()), ['g', 'k', 'b']): \n    for sample, style in (('train', '--'), ('test', '-')):\n        sample_score_mean = -results['mean_%s_%s' % (sample, scorer)] if scoring[scorer]=='neg_log_loss' else results['mean_%s_%s' % (sample, scorer)]\n        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n                        sample_score_mean + sample_score_std,\n                        alpha=0.1 if sample == 'test' else 0, color=color)\n        ax.plot(X_axis, sample_score_mean, style, color=color,\n                alpha=1 if sample == 'test' else 0.7,\n                label=\"%s (%s)\" % (scorer, sample))\n\n    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n    best_score = -results['mean_test_%s' % scorer][best_index] if scoring[scorer]=='neg_log_loss' else results['mean_test_%s' % scorer][best_index]\n        \n    # Plot a dotted vertical line at the best score for that scorer marked by x\n    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n\n    # Annotate the best score for that scorer\n    ax.annotate(\"%0.2f\" % best_score,\n                (X_axis[best_index], best_score + 0.005))\n\nplt.legend(loc=\"best\")\nplt.grid('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\n\n#Define simple model\n###############################################################################\nC = np.arange(1e-05, 5.5, 0.1)\nscoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\nlog_reg = LogisticRegression()\n\n#Simple pre-processing estimators\n###############################################################################\nstd_scale = StandardScaler(with_mean=False, with_std=False)\n#std_scale = StandardScaler()\n\n#Defining the CV method: Using the Repeated Stratified K Fold\n###############################################################################\n\nn_folds=5\nn_repeats=5\n\nrskfold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=n_repeats, random_state=2)\n\n#Creating simple pipeline and defining the gridsearch\n###############################################################################\n\nlog_clf_pipe = Pipeline(steps=[('scale',std_scale), ('clf',log_reg)])\n\nlog_clf = GridSearchCV(estimator=log_clf_pipe, cv=rskfold,\n              scoring=scoring, return_train_score=True,\n              param_grid=dict(clf__C=C), refit='Accuracy')\n\nlog_clf.fit(X, y)\nresults = log_clf.cv_results_\n\nprint('='*20)\nprint(\"best params: \" + str(log_clf.best_estimator_))\nprint(\"best params: \" + str(log_clf.best_params_))\nprint('best score:', log_clf.best_score_)\nprint('='*20)\n\nplt.figure(figsize=(10, 10))\nplt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",fontsize=16)\n\nplt.xlabel(\"Inverse of regularization strength: C\")\nplt.ylabel(\"Score\")\nplt.grid()\n\nax = plt.axes()\nax.set_xlim(0, C.max()) \nax.set_ylim(0.35, 0.95)\n\n# Get the regular numpy array from the MaskedArray\nX_axis = np.array(results['param_clf__C'].data, dtype=float)\n\nfor scorer, color in zip(list(scoring.keys()), ['g', 'k', 'b']): \n    for sample, style in (('train', '--'), ('test', '-')):\n        sample_score_mean = -results['mean_%s_%s' % (sample, scorer)] if scoring[scorer]=='neg_log_loss' else results['mean_%s_%s' % (sample, scorer)]\n        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n                        sample_score_mean + sample_score_std,\n                        alpha=0.1 if sample == 'test' else 0, color=color)\n        ax.plot(X_axis, sample_score_mean, style, color=color,\n                alpha=1 if sample == 'test' else 0.7,\n                label=\"%s (%s)\" % (scorer, sample))\n\n    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n    best_score = -results['mean_test_%s' % scorer][best_index] if scoring[sorer]=='neg_log_loss' else results['mean_test_%s' % scorer][best_index]\n        \n    # Plot a dotted vertical line at the best score for that scorer marked by x\n    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n\n    # Annotate the best score for that scorer\n    ax.annotate(\"%0.2f\" % best_score,\n                (X_axis[best_index], best_score + 0.005))\n\nplt.legend(loc=\"best\")\nplt.grid('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test['Transported_True'] = log_clf.predict(final_test[Selected_features])\nfinal_test['PassengerId'] = test_df['PassengerId']\n\nsubmission = final_test[['PassengerId','Transported_True']]\n\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}